#!/bin/sh

## Performance without new experiences generated by DDPG
## On a filtered replay buffer

PARALLEL_MAX=8

MEAN_BATCH_SIZE=8

POLICY_NAME="DDPG"

RESET_RADIUS=1

FILTER_RADIUS=1

TAU=0.5

DIMENSION=2

ROOT_DIR="$(pwd)/"

RESULT_DIR="results/"

MODE="velocity"

TITLE="learning timesteps"

X_LABEL="learning timesteps"

Y_LABEL="reward/step"

BUFFER_SIZE=5000


run_training()
{
  OUTPUT_DIR="${ROOT_DIR}${RESULT_DIR}${POLICY_NAME}_n$1_$2"

  COMMAND="python ../../learn_multidimensional.py\
    --policy_name=$POLICY_NAME\
    --exploration_timesteps=${BUFFER_SIZE}\
    --learning_timesteps=$1\
    --buffer_size=${BUFFER_SIZE}\
    --eval_freq=$1\
    --tau=$TAU\
    --dimensions=$DIMENSION\
    --${MODE}\
    --save\
    --no-render\
    --no-new-exp\
    --output=${OUTPUT_DIR}\
    --reset_radius=${RESET_RADIUS}\
    --filter\
    --filter_radius=${FILTER_RADIUS}"

  eval ${COMMAND}
}


PARALLEL=0

for i in 500 1000 2000 4000 8000 16000 32000
do
    for j in $(seq 0 $(($MEAN_BATCH_SIZE-1)))
    do
        PARALLEL=$(($PARALLEL+1))
        if [ $PARALLEL -ge $PARALLEL_MAX ]
        then
            echo "Training $i $j"
            run_training $i $j
            PARALLEL=0
        else
            echo "Training $i $j"
            run_training $i $j &
        fi
    done
done


COMMAND2="python ../plot_evaluations.py\
    --directory=$RESULT_DIR\
    --batch_size=$MEAN_BATCH_SIZE\
    --title='$TITLE'\
    --x_label='$X_LABEL'\
    --y_label='$Y_LABEL'\
    --log_scale"

eval ${COMMAND2}

COMMAND3="python ../plot_average_q.py\
    --directory=$RESULT_DIR\
    --batch_size=$MEAN_BATCH_SIZE\
    --eval_freq=1"

eval ${COMMAND3}

COMMAND4="python ../plot_average_pi.py\
    --directory=$RESULT_DIR\
    --batch_size=$MEAN_BATCH_SIZE\
    --eval_freq=1"

eval ${COMMAND4}
